{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb55562-cd14-4830-b4eb-fee58c443ae0",
   "metadata": {},
   "source": [
    "# Alpaca LoRA 7B\n",
    "\n",
    "- github: [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora)\n",
    "- huggingface: [tloen/alpaca-lora-7b](https://huggingface.co/tloen/alpaca-lora-7b)\n",
    "\n",
    "## Download\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/tloen/alpaca-lora\n",
    "git clone https://huggingface.co/tloen/alpaca-lora-7b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb56b2b-5479-4f1f-9a50-82bb7c38266c",
   "metadata": {},
   "source": [
    "### Python libraries\n",
    "\n",
    "- [requirements.txt](https://github.com/tloen/alpaca-lora/blob/main/requirements.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a320b8cf-f61a-4757-8fe2-ea21dd3f642b",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9028d7-820e-41f8-9a54-9cb6763f6130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keanu/.pyenv/versions/3.11.1/envs/myllm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416cc0b2-29c7-4337-9fe5-95a81a79a5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer.model: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500k/500k [00:00<00:00, 31.3MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.00/2.00 [00:00<00:00, 1.74kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 141/141 [00:00<00:00, 127kB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    \"decapoda-research/llama-7b-hf\", add_eos_token=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8385c4be-054a-4733-bff5-2241ba1859cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c18ee55-2d17-4ca1-96b5-880b766bcac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/keanu/.cache/huggingface/datasets/json/default-78451e3fc4898e05/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
      "Extracting data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1506.57it/s]\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/keanu/.cache/huggingface/datasets/json/default-78451e3fc4898e05/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 310.97it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=\"alpaca-lora/alpaca_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913cc98-a5ca-4e28-be49-eed13196b98c",
   "metadata": {},
   "source": [
    "python finetune.py \\\n",
    "    --base_model='decapoda-research/llama-7b-hf' \\\n",
    "    --num_epochs=10 \\\n",
    "    --cutoff_len=512 \\\n",
    "    --group_by_length \\\n",
    "    --output_dir='./lora-alpaca' \\\n",
    "    --lora_target_modules='[q_proj,k_proj,v_proj,o_proj]' \\\n",
    "    --lora_r=16 \\\n",
    "    --micro_batch_size=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acc7c2-e320-49c2-a53e-7cce3eb92ce3",
   "metadata": {},
   "source": [
    "```bash\n",
    "python generate.py \\\n",
    "    --base_model 'decapoda-research/llama-7b-hf' \\\n",
    "    --lora_weights 'tloen/alpaca-lora-7b'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309d3ed-1728-4b40-aaa3-cf84e0e6c660",
   "metadata": {},
   "source": [
    "Running on local URL:  http://0.0.0.0:7860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10631544-9e07-4043-ac8b-82ddc76f52aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
